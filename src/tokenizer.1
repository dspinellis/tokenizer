.TH TOKENIZER 1 2023-07-14
.SH NAME
\fBtokenizer\fR \(en convert source code into integer vectors
.SH SYNOPSIS
\fBtokenizer\fR [\fB\-acgs\fR | \fB-B\fR | \fB-b\fP] [\fB\-fLV\fP] [\fB\-i \fIfile\fR] [\fB\-l \fIlang\fR] [\fB\-o \fIopt\fR] [\fB\-t \fIsep\fR] [\fIfile ...\fR]
.SH DESCRIPTION
The \fBtokenizer\fR utility converts source code specified as files in
its command line or provided through its standard input into one of several
supported output formats.

By default the \fItokenizer\fR outputs numerical token codes.
The correspondence between tokens and values is not a stable API,
but it can always be established by running \fItokenizer\fP \fb-L\fP.

.RS 3
.IP \(bu
Characters are output as values in the range 0\(en255.
.IP \(bu
The language's keywords, other multi-character tokens (e.g. \fC+=\fP),
and numbers are output as values in the ranges that can be seen by running
\fItokenizer\fP \fb-L\fP.
The numbers for the same keywords are the same between different languages,
allowing the tokenizer to be used to train models through transfer learning.
.IP \(bu
Numbers are output on a base-ten logarithmic scale centered around zero
and extending by less than 400 values around it.
.IP \(bu
Other constants (e.g. characters and strings) are represented as an integer
corresponding to that token type.
.IP \(bu
Comments are mapped into a single integer.
.IP \(bu
White space is not included in the output, unless the \fB-a\fP
option is specified.
.IP \(bu
Identifiers are output as a value starting at \fCFIRST_IDENTIFIER\fP.
Identifiers with the same name within a scope get the same value.
Identifiers in outer scopes are visible with the same value in inner scopes.
Identfiers in first seen in a scope are not visible outside that scope.
.IP \(bu
When the \fB-a\fP option is specified, comments and strings have their
token value followed by a value of their content's hash
as a value starting at \fCFIRST_HASH_CONTENT\fP.
Moreover horizontal space (spaces and tabs) is output, run length
encoded as seen in the output of the \fB-L\fP option.
.RE

The default form is suitable for training machine-learning models.
With global scoping, it is also well-suited for Type-1 (exact in code)
clone detection.

.SH OPTIONS
The behavior of the \fItokenizer\fR utility can be controlled
through the following command-line options.

.RS 3

.TP
.B "-a"
Output distinct token values for all input, including horizontal white space
and the content of strings and comments.
This option can be used for Type-0 (exact in all text) clone detection.

.TP
.B -B
Output the type of each token (ID, KW, NUM, or TOK) and the actual token,
one entry per line.
Comments and strings are output with their content replaced by an
ellipsis (...).
All other tokens are output in their original form.

.TP
.B -b
Similar to the \fB-B\fP output format, but without the token type
prefix.
This output format is suitable for passing to line-difference programs
in order to process the code at the level of individual tokens.

.TP
.B -c
Compress token values so that all identifiers and numbers are treated
as the same.
In the numeric output form
all numbers are represented with the value corresponding to the token symbol
\fCANY_NUMBER\fP
and all identifiers with the value corresponding to the token symbol
\fCANY_IDENTIFIER\fP.
This option can be used for Type-2 (near or renamed) clone detection.

.TP
.B -f
Identify each read file, before outputting its tokens.
The file name is output on a separate line prefixed with the letter "F".
This is the same convention as that expected by the clone detector
.IR mpcd (1).

.TP
.B -g
Global scoping.
All identifiers with the same name are allocated to the same
token, irrespective of their scope.
This option is useful for Type-1 (exact in code) clone detection.

.TP
.BI "-i " file
Process the files listed in the specified file.
If the file name is "\(en", then the list of files to process
is read from the program's standard input.

.TP
.B -L
List the values and corresponding strings associated with the
\fItokenizer\fP tokens, and then exit.

.TP
.BI "-l " lang
Specify the input language.
Currently the following languages are supported:
\fIC\fP,
\fICSharp\fP (or \fIC#\fP),
\fIC++\fP,
\fIGo\fP,
\fIJava\fP,
\fIJavaScript\fP,
\fIPHP\fP,
\fIPython\fP,
\fIRust\fP,
\fITypeScript\fP.

.TP
.BI "-o " opt
Specify a language-specific processing option.
Multiple \fB-o\fP arguments may be provided.
The following processing options are supported.

.RS 3

.TP
.B file
Output a single vector for the whole file.

.TP
.B line
Output one vector per input line.
Input and output lines are synchronized, allowing the tracking
of tokens to their original line position.

.TP
.B method
Output a vector for the contents of each method.

.TP
.B statement
Output a vector for each statement.
.LP
.RE

.TP
.B -s
Output symbolic token values.
.RS 3
.IP \(bu
Single character tokens and reserved words are output in their original form.
.IP \(bu
Other language tokens are output as a symbol representing them.
.IP \(bu
Numbers are output in scientific notation as 1, prefixed by "~",
and followed by a varying exponent according to the number's base-ten logarithm.
.IP \(bu
Identifiers are prefixed by "ID:" and followed by an integer corresponding to
the identifier number defined for numeric token values.
.IP \(bu
When the \fB-a\fP option is specified, comments, strings, and single-quote
literals have their
token followed by a value of their content's hash prefixed by "HASH:".
.RE

.TP
.BI "-t " sep
Specify the separator character for non-line output.
By default this is tab for numeric tokens and space for symbolic output.

.TP
.B "-V"
Display the program's version number and exit.

.RE

.SH EXAMPLES
.PP
Process a C file to obtain symbolic output.
.ft C
.nf
tokenizer -l C -s file.c
.ft P
.fi

.PP
Process a Java file obtaining a numeric vector per method.
.ft C
.nf
tokenizer -l Java -o method File.java
.ft P
.fi

.PP
Produce a token-by-token difference between the current version of the
file \fCtokenizer.cpp\fP and the one in version v1.1.
.ft C
.nf
diff <(git show v1.1:./tokenizer.cpp | tokenizer -l C++ -b) \\
  <(tokenizer -l C++ -b tokenizer.cpp)
.ft P
.fi

.PP
List Type-2 (near or renamed) clones in the \fItokenizer\fP source code.
.ft C
.nf
tokenizer -l C++ -c -f -o line *.cpp *.h | mpcd
.ft P
.fi

.SH DIAGNOSTICS
An error is displayed when an end of file is encountered while processing
a block comment or a character or string literal.

.SH SEE ALSO
.IR mpcd (1)
\(em modular performant clone detector.

.SH AUTHORS
Written by Diomidis Spinellis.

.SH BUGS
The tokenizer is more permissive than the corresponding language specifications.
For example, number literals can contain arbitrary letters in them,
in addition to the recognized \fC0x\fP and \fC0b\fP prefixes.
Also string and character literals can contain arbitrary backslash-escape
sequences, in addition the defined ones.
.PP
Continuation lines are not supported.
.PP
Non-ASCII identifiers are not supported.
.PP
The processing context may get confused by unbalanced braces occurring in
C preprocessor macro definitions.
.PP
The Python tokenizer does not support processing options and identifier
scoping.
.PP
The Rust tokenizer handles tuple indices and literal suffixes as separate
lexical elements (numbers and identifiers, respectively).
